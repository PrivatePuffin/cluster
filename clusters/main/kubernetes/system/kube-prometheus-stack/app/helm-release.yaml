---
# yaml-language-server: $schema=https://kubernetes-schemas.pages.dev/helm.toolkit.fluxcd.io/helmrelease_v2.json
apiVersion: helm.toolkit.fluxcd.io/v2
kind: HelmRelease
metadata:
  name: kube-prometheus-stack
  namespace: kube-prometheus-stack
spec:
  interval: 15m
  chart:
    spec:
      chart: kube-prometheus-stack
      version: 69.8.2
      sourceRef:
        kind: HelmRepository
        name: prometheus-community
        namespace: flux-system
      interval: 15m
  timeout: 20m
  maxHistory: 3
  install:
    createNamespace: true
    remediation:
      retries: 3
  upgrade:
    cleanupOnFail: true
    remediation:
      retries: 3
  uninstall:
    keepHistory: false
  values:
    crds:
      enabled: true
      upgradeJob:
        enabled: true
        forceConflicts: true
    cleanPrometheusOperatorObjectNames: true
    alertmanager:
      enabled: false
      ingress:
        enabled: true
        annotations:
          traefik.ingress.kubernetes.io/router.entrypoints: websecure
          cert-manager.io/cluster-issuer: le-prod
          cert-manager.io/private-key-rotation-policy: Always
          traefik.ingress.kubernetes.io/router.tls: 'true'
          traefik.ingress.kubernetes.io/router.middlewares: traefik-chain-basic@kubernetescrd,traefik-local@kubernetescrd
        tls:
          - hosts:
              - alertmanager.${DOMAIN_0}
            secretName: kube-prometheus-stack-kube-prometheus-stack
        hosts:
          - alertmanager.${DOMAIN_0}
      alertmanagerSpec:
        alertmanagerConfiguration:
          name: alertmanager
          global:
            resolveTimeout: 5m
        externalUrl: https://alertmanager.${DOMAIN_0}
    kubeEtcd:
      service:
        selector:
          component: kube-apiserver # etcd runs on control plane nodes
    kubeProxy:
      enabled: false
    prometheus:
      ingress:
        enabled: true
        annotations:
          cert-manager.io/cluster-issuer: le-prod
          cert-manager.io/private-key-rotation-policy: Always
        tls:
          - hosts:
              - prometheus.${DOMAIN_0}
            secretName: kube-prometheus-stack-kube-prometheus-stack
        hosts:
          - prometheus.${DOMAIN_0}
      # Service for thanos service discovery on sidecar
      # Enable this can make Thanos Query can use
      # `--store=dnssrv+_grpc._tcp.${kube-prometheus-stack.fullname}-thanos-discovery.${namespace}.svc.cluster.local` to discovery
      # Thanos sidecar on prometheus nodes
      thanosService:
        enabled: true
        # annotations:
        #   metallb.io/ip-allocated-from-pool: main
        #   metallb.io/loadBalancerIPs: "${PROM_THANOS_IP}"
        #   metallb.universe.tf/ip-allocated-from-pool: main
        #   "lbipam.cilium.io/ips": ${PROM_THANOS_IP}
      # ServiceMonitor to scrape Sidecar metrics
      # Needs thanosService to be enabled as well
      thanosServiceMonitor:
        enabled: true
      thanosIngress:
        enabled: true
        annotations:
          cert-manager.io/cluster-issuer: le-prod
          cert-manager.io/private-key-rotation-policy: Always
        tls:
          - hosts:
              - prometheus-thanos.${DOMAIN_0}
            secretName: kube-prometheus-stack-kube-prometheus-stack-thanos
        hosts:
          - prometheus-thanos.${DOMAIN_0}
        paths:
          - /
        pathType: "Prefix"
      prometheusSpec:
        disableCompaction: true
        podMonitorSelectorNilUsesHelmValues: false
        probeSelectorNilUsesHelmValues: false
        ruleSelectorNilUsesHelmValues: false
        scrapeConfigSelectorNilUsesHelmValues: false
        serviceMonitorSelectorNilUsesHelmValues: false
        enableAdminAPI: true
        walCompression: true
        enableFeatures:
          - memory-snapshot-on-shutdown
        # Prometheus metrics retention time in PV
        retention: 6h
        retentionSize: 50GB
        # External labels to add to any time series or 
        # alerts when communicating with external systems
        externalLabels:
          cluster: cluster_main
          env: prod   
        # High availability
        replicas: 2 
        resources:
          requests:
            cpu: 100m
          limits:
            memory: 2000Mi
        storageSpec:
          volumeClaimTemplate:
            spec:
              resources:
                requests:
                  storage: 60Gi
        thanos:
          objectStorageConfig:
            secret:
              type: S3
              config:
                bucket: "${S3PREFIX}-thanos"
                endpoint: "192.168.10.21:9000"
                insecure: true
                access_key: "${S3ID_THANOS}"
                secret_key: "${S3KEY_THANOS}"

  

    prometheus-node-exporter:
      fullnameOverride: node-exporter
      prometheus:
        monitor:
          enabled: true
          relabelings:
            - action: replace
              regex: (.*)
              replacement: $1
              sourceLabels: ["__meta_kubernetes_pod_node_name"]
              targetLabel: kubernetes_node
    kube-state-metrics:
      fullnameOverride: kube-state-metrics
      # metricLabelsAllowlist:
      #   - pods=[*]
      #   - deployments=[*]
      #   - persistentvolumeclaims=[*]
      prometheus:
        monitor:
          enabled: true
          relabelings:
            - action: replace
              regex: (.*)
              replacement: $1
              sourceLabels: ["__meta_kubernetes_pod_node_name"]
              targetLabel: kubernetes_node
    grafana:
      enabled: false
      forceDeployDashboards: true
      defaultDashboardsEnabled: true
      forceDeployDatasources: true
    #additionalPrometheusRulesMap:
    #  dockerhub-rules:
    #    groups:
    #      - name: dockerhub
    #        rules:
    #          - alert: DockerhubRateLimitRisk
    #            annotations:
    #              summary: Kubernetes cluster Dockerhub rate limit risk
    #            expr: count(time() - container_last_seen{image=~"(docker.io).*",container!=""} < 30) > 100
    #            labels:
    #              severity: critical
    #  oom-rules:
    #    groups:
    #      - name: oom
    #        rules:
    #          - alert: OomKilled
    #            annotations:
    #              summary: Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.
    #            expr: (kube_pod_container_status_restarts_total - kube_pod_container_status_restarts_total offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{reason="OOMKilled"}[10m]) == 1
    #            labels:
    #              severity: critical
    #  zfs-rules:
    #    groups:
    #      - name: zfs
    #        rules:
    #          - alert: ZfsUnexpectedPoolState
    #            annotations:
    #              summary: ZFS pool {{$labels.zpool}} on {{$labels.instance}} is in a unexpected state {{$labels.state}}
    #            expr: node_zfs_zpool_state{state!="online"} > 0
    #            labels:
    #              severity: critical